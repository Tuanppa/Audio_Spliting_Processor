# Audio Processor - Audio to Text Segmentation

á»¨ng dá»¥ng Python Ä‘á»ƒ chuyá»ƒn audio thÃ nh text vÃ  tÃ¡ch thÃ nh cÃ¡c Ä‘oáº¡n nhá» theo cÃ¢u, phá»¥c vá»¥ cho viá»‡c táº¡o dataset AI.

## ğŸ¯ TÃ­nh nÄƒng

- âœ… Chuyá»ƒn audio thÃ nh text vá»›i timestamp chÃ­nh xÃ¡c (sá»­ dá»¥ng Whisper)
- âœ… Tá»± Ä‘á»™ng tÃ¡ch cÃ¢u vÃ  merge thÃ nh segments há»£p lÃ½
- âœ… Cáº¯t audio theo tá»«ng cÃ¢u
- âœ… Export ra nhiá»u Ä‘á»‹nh dáº¡ng (individual files, manifest JSON)
- âœ… Xá»­ lÃ½ batch nhiá»u file
- âœ… Há»— trá»£ triá»ƒn khai Ä‘a mÃ¡y (distributed processing)
- âœ… Há»— trá»£ GPU acceleration
- âœ… Logging vÃ  error handling chi tiáº¿t

## ğŸ“‹ YÃªu cáº§u há»‡ thá»‘ng

### CÆ¡ báº£n
- Python 3.8+
- RAM: 4GB+ (8GB+ cho model large)
- Disk: 5GB+ (cho models)

### Khuyáº¿n nghá»‹ cho xá»­ lÃ½ nhanh
- GPU: NVIDIA GPU vá»›i CUDA (RTX 3060+)
- RAM: 16GB+
- SSD storage

## ğŸš€ CÃ i Ä‘áº·t

### BÆ°á»›c 1: Clone/Download project

```bash
# Náº¿u cÃ³ git
git clone <repository-url>
cd audio_processor

# Hoáº·c download vÃ  giáº£i nÃ©n
```

### BÆ°á»›c 2: Táº¡o virtual environment

```bash
# Táº¡o virtual environment
python -m venv venv

# KÃ­ch hoáº¡t (Linux/Mac)
source venv/bin/activate

# KÃ­ch hoáº¡t (Windows)
venv\Scripts\activate
```

### BÆ°á»›c 3: CÃ i Ä‘áº·t dependencies

#### Cho CPU (khÃ´ng cÃ³ GPU)
```bash
pip install -r requirements.txt
```

#### Cho GPU (NVIDIA CUDA 11.8)
```bash
pip install torch==2.1.0+cu118 torchaudio==2.1.0+cu118 --index-url https://download.pytorch.org/whl/cu118
pip install -r requirements.txt
```

### BÆ°á»›c 4: Download NLTK data
```bash
python -c "import nltk; nltk.download('punkt')"
```

### BÆ°á»›c 5: Kiá»ƒm tra cÃ i Ä‘áº·t
```bash
python main.py --help
```

## ğŸ“– Sá»­ dá»¥ng

### 1. Xá»­ lÃ½ má»™t file audio

```bash
python main.py --input sample.wav --output ./output
```

**Káº¿t quáº£:**
```
output/
â”œâ”€â”€ segment_0001.wav
â”œâ”€â”€ segment_0001.txt
â”œâ”€â”€ segment_0002.wav
â”œâ”€â”€ segment_0002.txt
â”œâ”€â”€ ...
â”œâ”€â”€ full_transcript.txt
â”œâ”€â”€ full_transcript.json
â”œâ”€â”€ manifest.json
â””â”€â”€ metadata.json
```

### 2. Xá»­ lÃ½ batch nhiá»u file

```bash
# Äáº·t táº¥t cáº£ audio vÃ o thÆ° má»¥c input/
mkdir input
cp *.wav input/

# Cháº¡y batch processing
python main.py --batch --input-dir ./input --output-dir ./output
```

### 3. Sá»­ dá»¥ng model lá»›n hÆ¡n (chÃ­nh xÃ¡c hÆ¡n)

```bash
# Model base (default) - cÃ¢n báº±ng
python main.py --input sample.wav --model base

# Model small - chÃ­nh xÃ¡c hÆ¡n
python main.py --input sample.wav --model small

# Model medium - ráº¥t chÃ­nh xÃ¡c (cáº§n RAM nhiá»u)
python main.py --input sample.wav --model medium

# Model large - chÃ­nh xÃ¡c nháº¥t (cáº§n GPU máº¡nh)
python main.py --input sample.wav --model large --device cuda
```

### 4. TÃ¹y chá»‰nh Ä‘á»™ dÃ i segment

```bash
# Segment ngáº¯n nháº¥t 1s, dÃ i nháº¥t 20s
python main.py --input sample.wav --min-duration 1.0 --max-duration 20.0
```

### 5. Xem thá»‘ng kÃª

```bash
python main.py --stats ./output/sample
```

**Output:**
```
============================================================
PROCESSING STATISTICS
============================================================
Total Segments: 45
Total Duration: 180.25s (3.00 minutes)
Average Segment: 4.01s
Shortest Segment: 1.20s
Longest Segment: 12.50s
Total Words: 850
Avg Words/Segment: 18.9
============================================================
```

## ğŸ–¥ï¸ Triá»ƒn khai Ä‘a mÃ¡y

DÃ¹ng Ä‘á»ƒ xá»­ lÃ½ lÆ°á»£ng lá»›n audio trÃªn nhiá»u mÃ¡y tÃ­nh.

### Setup

1. **Táº¡o shared directory** (network drive hoáº·c NAS)
   ```
   /shared/
   â”œâ”€â”€ input/     # Äáº·t audio files vÃ o Ä‘Ã¢y
   â””â”€â”€ output/    # Káº¿t quáº£ sáº½ Ä‘Æ°á»£c lÆ°u á»Ÿ Ä‘Ã¢y
   ```

2. **Cháº¡y worker trÃªn má»—i mÃ¡y**

   ```bash
   # MÃ¡y 1 (CPU)
   python worker.py --id worker_01 --input /shared/input --output /shared/output --model base --device cpu
   
   # MÃ¡y 2 (GPU)
   python worker.py --id worker_02 --input /shared/input --output /shared/output --model large --device cuda
   
   # MÃ¡y 3 (CPU)
   python worker.py --id worker_03 --input /shared/input --output /shared/output --model small --device cpu
   ```

3. **Copy audio files vÃ o shared/input/**
   - Workers sáº½ tá»± Ä‘á»™ng phÃ¡t hiá»‡n vÃ  xá»­ lÃ½
   - KhÃ´ng xung Ä‘á»™t (má»—i file chá»‰ Ä‘Æ°á»£c xá»­ lÃ½ bá»Ÿi 1 worker)

### CÆ¡ cháº¿ hoáº¡t Ä‘á»™ng

1. Worker scan `shared/input/` Ä‘á»ƒ tÃ¬m file má»›i
2. Lock file báº±ng cÃ¡ch táº¡o `.processing` marker
3. Xá»­ lÃ½ file
4. LÆ°u káº¿t quáº£ vÃ o `shared/output/`
5. Táº¡o `.done` marker
6. Láº·p láº¡i

### Monitoring

Xem log cá»§a worker:
```bash
python worker.py --id worker_01 --input /shared/input --output /shared/output --log-file worker_01.log -v
```

## âš™ï¸ Cáº¥u hÃ¬nh nÃ¢ng cao

### Táº¡o file config tÃ¹y chá»‰nh

```python
from config import AppConfig, WhisperConfig, AudioConfig

# Táº¡o config
config = AppConfig(
    whisper=WhisperConfig(
        model_size="large",
        device="cuda"
    ),
    audio=AudioConfig(
        min_segment_duration=2.0,
        max_segment_duration=15.0,
        format="mp3"  # Export ra mp3 thay vÃ¬ wav
    )
)

# LÆ°u config
from config import save_config
save_config(config, "my_config.json")

# Load vÃ  dÃ¹ng
from config import load_config
config = load_config("my_config.json")
```

### Sá»­ dá»¥ng trong Python code

```python
from processor import AudioProcessor
from config import AppConfig

# Khá»Ÿi táº¡o
config = AppConfig()
processor = AudioProcessor(config)

# Xá»­ lÃ½ file
result = processor.process_single_file("sample.wav", "./output")

# Xá»­ lÃ½ batch
results = processor.process_batch("./input", "./output")

# Xem stats
stats = processor.get_processing_stats("./output/sample")
print(stats)
```

## ğŸ“Š Format Output

### 1. Individual Files
```
segment_0001.wav      # Audio Ä‘oáº¡n 1
segment_0001.txt      # Text Ä‘oáº¡n 1
segment_0002.wav      # Audio Ä‘oáº¡n 2
segment_0002.txt      # Text Ä‘oáº¡n 2
...
```

### 2. Full Transcript (full_transcript.txt)
```
[0.00 - 3.45] This is the first sentence.
[3.45 - 7.89] This is the second sentence.
[7.89 - 12.30] This is the third sentence.
...
```

### 3. Manifest (manifest.json)
```json
{
  "total_segments": 45,
  "total_duration": 180.25,
  "segments": [
    {
      "id": 0,
      "audio_file": "segment_0001.wav",
      "text_file": "segment_0001.txt",
      "text": "This is the first sentence.",
      "start": 0.0,
      "end": 3.45,
      "duration": 3.45
    },
    ...
  ]
}
```

### 4. Metadata (metadata.json)
```json
{
  "status": "success",
  "input_file": "sample.wav",
  "output_dir": "./output/sample",
  "total_segments": 45,
  "total_duration": 180.25,
  "processed_at": "2025-10-27T10:30:45",
  "config": {
    "whisper_model": "base",
    "sample_rate": 16000,
    "format": "wav"
  }
}
```

## ğŸ”§ Troubleshooting

### Lá»—i: "No module named 'whisper'"
```bash
pip install openai-whisper
```

### Lá»—i: CUDA out of memory
- DÃ¹ng model nhá» hÆ¡n: `--model small` hoáº·c `--model base`
- Hoáº·c dÃ¹ng CPU: `--device cpu`

### Lá»—i: "ffmpeg not found"
```bash
# Ubuntu/Debian
sudo apt-get install ffmpeg

# MacOS
brew install ffmpeg

# Windows
# Download tá»« https://ffmpeg.org/download.html
```

### Audio bá»‹ cáº¯t khÃ´ng chÃ­nh xÃ¡c
- TÄƒng `--min-duration`: `--min-duration 2.0`
- Thá»­ model lá»›n hÆ¡n: `--model medium`

### Xá»­ lÃ½ quÃ¡ cháº­m
- DÃ¹ng GPU: `--device cuda`
- DÃ¹ng model nhá» hÆ¡n: `--model tiny` hoáº·c `--model base`
- Triá»ƒn khai Ä‘a mÃ¡y vá»›i `worker.py`

## ğŸ“ Supported Audio Formats

- WAV (âœ… Recommended)
- MP3
- FLAC
- M4A
- OGG
- AAC

## ğŸ“ Tips & Best Practices

### 1. Chá»n model phÃ¹ há»£p

| Model  | Speed | Accuracy | RAM   | Use Case                    |
|--------|-------|----------|-------|-----------------------------|
| tiny   | âš¡âš¡âš¡ | â­       | 1GB   | Testing, quick preview      |
| base   | âš¡âš¡   | â­â­     | 1GB   | **Recommended for most use**|
| small  | âš¡     | â­â­â­   | 2GB   | Good balance                |
| medium | ğŸŒ    | â­â­â­â­ | 5GB   | High accuracy needed        |
| large  | ğŸŒğŸŒ  | â­â­â­â­â­| 10GB  | Best accuracy, need GPU     |

### 2. Chuáº©n bá»‹ audio tá»‘t

- Sample rate: 16kHz hoáº·c cao hÆ¡n
- Format: WAV (lossless) tá»‘t nháº¥t
- Audio rÃµ rÃ ng, Ã­t noise
- Mono channel (náº¿u cÃ³ thá»ƒ)

### 3. Segment duration

- **Ngáº¯n (0.5-3s)**: Tá»‘t cho speech synthesis training
- **Trung bÃ¬nh (3-10s)**: Tá»‘t cho general ASR training
- **DÃ i (10-30s)**: Tá»‘t cho podcast/lecture transcription

### 4. Distributed processing

- 1 mÃ¡y GPU máº¡nh (model large) + nhiá»u mÃ¡y CPU (model base)
- Monitor bÄƒng thÃ´ng network náº¿u dÃ¹ng network drive
- DÃ¹ng SSD cho shared directory náº¿u cÃ³ thá»ƒ

## ğŸ“„ License

MIT License - Free to use for any purpose

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Commit changes
4. Push to the branch
5. Create Pull Request

## ğŸ“§ Support

For issues and questions:
- GitHub Issues: [Create an issue]
- Email: your-email@example.com

## ğŸ™ Acknowledgments

- OpenAI Whisper - Speech recognition model
- Stable-ts - Improved timestamp alignment
- PyDub - Audio processing
- NLTK - Natural language processing

---

**Happy Processing! ğŸµâ†’ğŸ“**
